{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PU Learning For News\n",
    "Initial work\n",
    "\n",
    "Mainly to start exploring how to vectorize texts and also identify true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\atin3\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\atin3\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\atin3\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\atin3\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\atin3\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atin3\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atin3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import preprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (20722, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>house dem aide ’ even see comey ’ letter jason...</td>\n",
       "      <td>house dem aide ’ even see comey ’ letter jason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>ever get feeling life circle roundabout rather...</td>\n",
       "      <td>flynn hillary clinton big woman campus breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>truth might get fired october 29 2016 tension ...</td>\n",
       "      <td>truth might get fired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>video 15 civilian killed single u airstrike id...</td>\n",
       "      <td>15 civilian killed single u airstrike identified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>print iranian woman sentenced six year prison ...</td>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title              author  \\\n",
       "id                                                                          \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2                   Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                 text  label  \\\n",
       "id                                                             \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1   Ever get the feeling your life circles the rou...      0   \n",
       "2   Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3   Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4   Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "id                                                      \n",
       "0   house dem aide ’ even see comey ’ letter jason...   \n",
       "1   ever get feeling life circle roundabout rather...   \n",
       "2   truth might get fired october 29 2016 tension ...   \n",
       "3   video 15 civilian killed single u airstrike id...   \n",
       "4   print iranian woman sentenced six year prison ...   \n",
       "\n",
       "                                          clean_title  \n",
       "id                                                     \n",
       "0   house dem aide ’ even see comey ’ letter jason...  \n",
       "1    flynn hillary clinton big woman campus breitbart  \n",
       "2                               truth might get fired  \n",
       "3    15 civilian killed single u airstrike identified  \n",
       "4   iranian woman jailed fictional unpublished sto...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"./cleaned_article_dataset.csv\"\n",
    "df = pd.read_csv(input_file, index_col=\"id\")\n",
    "df = preprocessing.turn_into_pu(df, 0.5)\n",
    "print(\"df shape:\", df.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing.test_train_split(df)\n",
    "y_train.index = X_train.index\n",
    "# y_test_true = df_raw.loc[y_test.index, 'label']\n",
    "\n",
    "X_train['tokens'] = X_train['cleaned_text'].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing through Document Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>len</th>\n",
       "      <th>neg_cleaned_text</th>\n",
       "      <th>neu_cleaned_text</th>\n",
       "      <th>pos_cleaned_text</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg_clean_title</th>\n",
       "      <th>neu_clean_title</th>\n",
       "      <th>pos_clean_title</th>\n",
       "      <th>compound</th>\n",
       "      <th>percent_stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>FBI Agent Accuses James Comey Of ‘Trampling On...</td>\n",
       "      <td>IWB</td>\n",
       "      <td>Washington, D.C. 20535-0001 \\nSir, \\nI am writ...</td>\n",
       "      <td>washington dc 205350001 sir writing regarding ...</td>\n",
       "      <td>fbi agent accuses james comey ‘ trampling rule...</td>\n",
       "      <td>[washington, dc, 205350001, sir, writing, rega...</td>\n",
       "      <td>535</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.9940</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.001869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>Mike Pence May Break With Donald Trump, Again,...</td>\n",
       "      <td>Yamiche Alcindor</td>\n",
       "      <td>COLUMBUS, Ind.  —   Gov. Mike Pence of Indiana...</td>\n",
       "      <td>columbus ind — gov mike penny indiana republic...</td>\n",
       "      <td>mike penny may break donald trump tax return n...</td>\n",
       "      <td>[columbus, ind, —, gov, mike, penny, indiana, ...</td>\n",
       "      <td>341</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>UN Has Another Opportunity to Condemn Cuba’s O...</td>\n",
       "      <td>Frances Martel</td>\n",
       "      <td>The United Nations Office of the High Commissi...</td>\n",
       "      <td>united nation office high commissioner human r...</td>\n",
       "      <td>un another opportunity condemn cuba ’ oppressi...</td>\n",
       "      <td>[united, nation, office, high, commissioner, h...</td>\n",
       "      <td>441</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.9985</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17811</th>\n",
       "      <td>Clinton “Fixer”: I Spiked Damaging Stories for...</td>\n",
       "      <td>Selwyn Duke</td>\n",
       "      <td>Email \\nClinton wins “by a landslide” — in the...</td>\n",
       "      <td>email clinton win “ landslide ” — corruption d...</td>\n",
       "      <td>clinton “ fixer ” spiked damaging story sexual...</td>\n",
       "      <td>[email, clinton, win, “, landslide, ”, —, corr...</td>\n",
       "      <td>879</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19853</th>\n",
       "      <td>ACLU Targets Jeff Sessions Won’t Defend Michae...</td>\n",
       "      <td>Joel B. Pollak</td>\n",
       "      <td>The American Civil Liberties Union (ACLU) want...</td>\n",
       "      <td>american civil liberty union aclu want senate ...</td>\n",
       "      <td>aclu target jeff session ’ defend michael flyn...</td>\n",
       "      <td>[american, civil, liberty, union, aclu, want, ...</td>\n",
       "      <td>312</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18388</th>\n",
       "      <td>Housing Starts News A Double Edged Sword and I...</td>\n",
       "      <td>Lee Adler</td>\n",
       "      <td>Housing Starts News A Double Edged Sword and I...</td>\n",
       "      <td>housing start news double edged sword pointed ...</td>\n",
       "      <td>housing start news double edged sword ’ pointe...</td>\n",
       "      <td>[housing, start, news, double, edged, sword, p...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18771</th>\n",
       "      <td>Donald Trump: The next President of the United...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump: The next President of the United...</td>\n",
       "      <td>donald trump next president united state ameri...</td>\n",
       "      <td>donald trump next president united state america</td>\n",
       "      <td>[donald, trump, next, president, united, state...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ronnie Allen</td>\n",
       "      <td>Show up at the polls and vote for Donald Trump...</td>\n",
       "      <td>show poll vote donald trump make sure vote cas...</td>\n",
       "      <td>[ERROR: Input is not a string]</td>\n",
       "      <td>[show, poll, vote, donald, trump, make, sure, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5319</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>Top New York Restaurants of 2016 - The New Yor...</td>\n",
       "      <td>Pete Wells</td>\n",
       "      <td>No one person can review every new restaurant ...</td>\n",
       "      <td>one person review every new restaurant new yor...</td>\n",
       "      <td>top new york restaurant 2016 new york time</td>\n",
       "      <td>[one, person, review, every, new, restaurant, ...</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15214</th>\n",
       "      <td>The New York Times N.F.L. Playoff Simulator (3...</td>\n",
       "      <td>Josh Katz and Kevin Quealy</td>\n",
       "      <td>How can my team make the N. F. L. playoffs? It...</td>\n",
       "      <td>team make n f l playoff ’ simple question answ...</td>\n",
       "      <td>new york time nfl playoff simulator 3rd annual...</td>\n",
       "      <td>[team, make, n, f, l, playoff, ’, simple, ques...</td>\n",
       "      <td>272</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13883 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "id                                                         \n",
       "3551   FBI Agent Accuses James Comey Of ‘Trampling On...   \n",
       "3609   Mike Pence May Break With Donald Trump, Again,...   \n",
       "9200   UN Has Another Opportunity to Condemn Cuba’s O...   \n",
       "17811  Clinton “Fixer”: I Spiked Damaging Stories for...   \n",
       "19853  ACLU Targets Jeff Sessions Won’t Defend Michae...   \n",
       "...                                                  ...   \n",
       "18388  Housing Starts News A Double Edged Sword and I...   \n",
       "18771  Donald Trump: The next President of the United...   \n",
       "2261                                                 NaN   \n",
       "10405  Top New York Restaurants of 2016 - The New Yor...   \n",
       "15214  The New York Times N.F.L. Playoff Simulator (3...   \n",
       "\n",
       "                           author  \\\n",
       "id                                  \n",
       "3551                          IWB   \n",
       "3609             Yamiche Alcindor   \n",
       "9200               Frances Martel   \n",
       "17811                 Selwyn Duke   \n",
       "19853              Joel B. Pollak   \n",
       "...                           ...   \n",
       "18388                   Lee Adler   \n",
       "18771                         NaN   \n",
       "2261                 Ronnie Allen   \n",
       "10405                  Pete Wells   \n",
       "15214  Josh Katz and Kevin Quealy   \n",
       "\n",
       "                                                    text  \\\n",
       "id                                                         \n",
       "3551   Washington, D.C. 20535-0001 \\nSir, \\nI am writ...   \n",
       "3609   COLUMBUS, Ind.  —   Gov. Mike Pence of Indiana...   \n",
       "9200   The United Nations Office of the High Commissi...   \n",
       "17811  Email \\nClinton wins “by a landslide” — in the...   \n",
       "19853  The American Civil Liberties Union (ACLU) want...   \n",
       "...                                                  ...   \n",
       "18388  Housing Starts News A Double Edged Sword and I...   \n",
       "18771  Donald Trump: The next President of the United...   \n",
       "2261   Show up at the polls and vote for Donald Trump...   \n",
       "10405  No one person can review every new restaurant ...   \n",
       "15214  How can my team make the N. F. L. playoffs? It...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "id                                                         \n",
       "3551   washington dc 205350001 sir writing regarding ...   \n",
       "3609   columbus ind — gov mike penny indiana republic...   \n",
       "9200   united nation office high commissioner human r...   \n",
       "17811  email clinton win “ landslide ” — corruption d...   \n",
       "19853  american civil liberty union aclu want senate ...   \n",
       "...                                                  ...   \n",
       "18388  housing start news double edged sword pointed ...   \n",
       "18771  donald trump next president united state ameri...   \n",
       "2261   show poll vote donald trump make sure vote cas...   \n",
       "10405  one person review every new restaurant new yor...   \n",
       "15214  team make n f l playoff ’ simple question answ...   \n",
       "\n",
       "                                             clean_title  \\\n",
       "id                                                         \n",
       "3551   fbi agent accuses james comey ‘ trampling rule...   \n",
       "3609   mike penny may break donald trump tax return n...   \n",
       "9200   un another opportunity condemn cuba ’ oppressi...   \n",
       "17811  clinton “ fixer ” spiked damaging story sexual...   \n",
       "19853  aclu target jeff session ’ defend michael flyn...   \n",
       "...                                                  ...   \n",
       "18388  housing start news double edged sword ’ pointe...   \n",
       "18771   donald trump next president united state america   \n",
       "2261                      [ERROR: Input is not a string]   \n",
       "10405         top new york restaurant 2016 new york time   \n",
       "15214  new york time nfl playoff simulator 3rd annual...   \n",
       "\n",
       "                                                  tokens   len  \\\n",
       "id                                                               \n",
       "3551   [washington, dc, 205350001, sir, writing, rega...   535   \n",
       "3609   [columbus, ind, —, gov, mike, penny, indiana, ...   341   \n",
       "9200   [united, nation, office, high, commissioner, h...   441   \n",
       "17811  [email, clinton, win, “, landslide, ”, —, corr...   879   \n",
       "19853  [american, civil, liberty, union, aclu, want, ...   312   \n",
       "...                                                  ...   ...   \n",
       "18388  [housing, start, news, double, edged, sword, p...    32   \n",
       "18771  [donald, trump, next, president, united, state...    93   \n",
       "2261   [show, poll, vote, donald, trump, make, sure, ...    26   \n",
       "10405  [one, person, review, every, new, restaurant, ...  1147   \n",
       "15214  [team, make, n, f, l, playoff, ’, simple, ques...   272   \n",
       "\n",
       "       neg_cleaned_text  neu_cleaned_text  pos_cleaned_text  compound  \\\n",
       "id                                                                      \n",
       "3551              0.180             0.727             0.093   -0.9940   \n",
       "3609              0.051             0.889             0.060    0.5256   \n",
       "9200              0.261             0.651             0.088   -0.9985   \n",
       "17811             0.085             0.784             0.131    0.9773   \n",
       "19853             0.047             0.743             0.210    0.9954   \n",
       "...                 ...               ...               ...       ...   \n",
       "18388             0.061             0.716             0.223    0.7430   \n",
       "18771             0.000             0.737             0.263    0.9810   \n",
       "2261              0.000             0.754             0.246    0.7579   \n",
       "10405             0.032             0.810             0.158    0.9993   \n",
       "15214             0.045             0.714             0.241    0.9958   \n",
       "\n",
       "       neg_clean_title  neu_clean_title  pos_clean_title  compound  \\\n",
       "id                                                                   \n",
       "3551             0.211            0.789            0.000   -0.3400   \n",
       "3609             0.000            1.000            0.000    0.0000   \n",
       "9200             0.194            0.597            0.209    0.0516   \n",
       "17811            0.231            0.769            0.000   -0.5106   \n",
       "19853            0.000            1.000            0.000    0.0000   \n",
       "...                ...              ...              ...       ...   \n",
       "18388            0.000            1.000            0.000    0.0000   \n",
       "18771            0.000            0.682            0.318    0.4215   \n",
       "2261             0.407            0.593            0.000   -0.5319   \n",
       "10405            0.000            0.795            0.205    0.2023   \n",
       "15214            0.000            1.000            0.000    0.0000   \n",
       "\n",
       "       percent_stop  \n",
       "id                   \n",
       "3551       0.001869  \n",
       "3609       0.000000  \n",
       "9200       0.000000  \n",
       "17811      0.000000  \n",
       "19853      0.000000  \n",
       "...             ...  \n",
       "18388      0.000000  \n",
       "18771      0.000000  \n",
       "2261       0.000000  \n",
       "10405      0.000000  \n",
       "15214      0.000000  \n",
       "\n",
       "[13883 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def sentiment_maker(df: pd.DataFrame, type:str):\n",
    "    df['sentiment'] = df[type].astype(str).apply(analyzer.polarity_scores)\n",
    "    df = pd.concat([df.drop(['sentiment'], axis=1), df['sentiment'].apply(pd.Series)], axis=1)\n",
    "    df.rename(columns={col: f\"{col}_{type}\" for col in [\"pos\", \"neu\", \"neg\"]}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def count_stop_words(tokens):\n",
    "    stop_word_count = sum(1 for word in tokens if word in stop_words)\n",
    "    return stop_word_count / len(tokens)\n",
    "\n",
    "X_vec = X_train.copy()\n",
    "X_vec['len'] = X_vec['tokens'].apply(lambda x: len(x))\n",
    "\n",
    "X_vec = sentiment_maker(X_vec, \"cleaned_text\")\n",
    "X_vec = sentiment_maker(X_vec, \"clean_title\")\n",
    "\n",
    "X_vec['percent_stop'] = X_vec['tokens'].apply(count_stop_words)\n",
    "X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>neg_cleaned_text</th>\n",
       "      <th>neu_cleaned_text</th>\n",
       "      <th>pos_cleaned_text</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg_clean_title</th>\n",
       "      <th>neu_clean_title</th>\n",
       "      <th>pos_clean_title</th>\n",
       "      <th>compound</th>\n",
       "      <th>percent_stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>What We Know About the Details of the Police S...</td>\n",
       "      <td>Richard Fausset and Alan Blinder</td>\n",
       "      <td>CHARLOTTE, N. C.  —   The fatal police shootin...</td>\n",
       "      <td>charlotte n c — fatal police shooting keith la...</td>\n",
       "      <td>know detail police shooting charlotte new york...</td>\n",
       "      <td>[charlotte, n, c, —, fatal, police, shooting, ...</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9978</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>Bernie Sanders’s New Political Group Is Met by...</td>\n",
       "      <td>Alan Rappeport and Yamiche Alcindor</td>\n",
       "      <td>Senator Bernie Sanders of Vermont, his preside...</td>\n",
       "      <td>senator bernie sander vermont presidential cam...</td>\n",
       "      <td>bernie sander ’ new political group met staff ...</td>\n",
       "      <td>[senator, bernie, sander, vermont, presidentia...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>The Great Wall Street/Washington Con Job: Part...</td>\n",
       "      <td>David Stockman</td>\n",
       "      <td>The Great Wall Street/Washington Con Job: Part...</td>\n",
       "      <td>great wall streetwashington con job part 5 rec...</td>\n",
       "      <td>great wall streetwashington con job part 5 rec...</td>\n",
       "      <td>[great, wall, streetwashington, con, job, part...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>Your Friday Evening Briefing: Hillary Clinton,...</td>\n",
       "      <td>Jonah Engel Bromwich and Dolores Morrison</td>\n",
       "      <td>(Want to get this briefing by email? Here’s th...</td>\n",
       "      <td>want get briefing email ’ good evening ’ lates...</td>\n",
       "      <td>friday evening briefing hillary clinton donald...</td>\n",
       "      <td>[want, get, briefing, email, ’, good, evening,...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15104</th>\n",
       "      <td>True the Vote’s Engelbrecht: U.S. on Verge of ...</td>\n",
       "      <td>Dan Riehl</td>\n",
       "      <td>Catherine Engelbrecht, president of True the V...</td>\n",
       "      <td>catherine engelbrecht president true vote talk...</td>\n",
       "      <td>true vote ’ engelbrecht u verge ‘ systemic ’ v...</td>\n",
       "      <td>[catherine, engelbrecht, president, true, vote...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.2075</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.7269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20278</th>\n",
       "      <td>‘Duck Dynasty’ Legacy: Real, Fake and Upfront ...</td>\n",
       "      <td>Neil Genzlinger</td>\n",
       "      <td>Interesting juxtaposition of the week: The AE ...</td>\n",
       "      <td>interesting juxtaposition week ae show “ duck ...</td>\n",
       "      <td>‘ duck dynasty ’ legacy real fake upfront new ...</td>\n",
       "      <td>[interesting, juxtaposition, week, ae, show, “...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>Evidence Reveals Possible Link Between Voting ...</td>\n",
       "      <td>Stefanie MacWilliams</td>\n",
       "      <td>Videos Evidence Reveals Possible Link Between ...</td>\n",
       "      <td>video evidence reveals possible link voting ma...</td>\n",
       "      <td>evidence reveals possible link voting machine ...</td>\n",
       "      <td>[video, evidence, reveals, possible, link, vot...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>Journalist facing 45 years in jail for filming...</td>\n",
       "      <td>stevew</td>\n",
       "      <td>Meet the journalist facing 45 years in jail fo...</td>\n",
       "      <td>meet journalist facing 45 year jail filming ta...</td>\n",
       "      <td>journalist facing 45 year jail filming tar san...</td>\n",
       "      <td>[meet, journalist, facing, 45, year, jail, fil...</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.9966</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>Comment on Canadian Man Slams Americans Who Do...</td>\n",
       "      <td>kryptodyne</td>\n",
       "      <td>Subscribe \\nA dumbfounded Canadian — Richard B...</td>\n",
       "      <td>subscribe dumbfounded canadian — richard brunt...</td>\n",
       "      <td>comment canadian man slam american ’ realize a...</td>\n",
       "      <td>[subscribe, dumbfounded, canadian, —, richard,...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10849</th>\n",
       "      <td>29 of Hillary's scandals: The early years</td>\n",
       "      <td>Jack Cashill</td>\n",
       "      <td>For those who are too young or too unwilling t...</td>\n",
       "      <td>young unwilling remember trip memory lane 1969...</td>\n",
       "      <td>29 hillary scandal early year</td>\n",
       "      <td>[young, unwilling, remember, trip, memory, lan...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.9882</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "id                                                         \n",
       "7048   What We Know About the Details of the Police S...   \n",
       "7891   Bernie Sanders’s New Political Group Is Met by...   \n",
       "3872   The Great Wall Street/Washington Con Job: Part...   \n",
       "6379   Your Friday Evening Briefing: Hillary Clinton,...   \n",
       "15104  True the Vote’s Engelbrecht: U.S. on Verge of ...   \n",
       "...                                                  ...   \n",
       "20278  ‘Duck Dynasty’ Legacy: Real, Fake and Upfront ...   \n",
       "13283  Evidence Reveals Possible Link Between Voting ...   \n",
       "7064   Journalist facing 45 years in jail for filming...   \n",
       "1936   Comment on Canadian Man Slams Americans Who Do...   \n",
       "10849          29 of Hillary's scandals: The early years   \n",
       "\n",
       "                                          author  \\\n",
       "id                                                 \n",
       "7048            Richard Fausset and Alan Blinder   \n",
       "7891         Alan Rappeport and Yamiche Alcindor   \n",
       "3872                              David Stockman   \n",
       "6379   Jonah Engel Bromwich and Dolores Morrison   \n",
       "15104                                  Dan Riehl   \n",
       "...                                          ...   \n",
       "20278                            Neil Genzlinger   \n",
       "13283                       Stefanie MacWilliams   \n",
       "7064                                      stevew   \n",
       "1936                                  kryptodyne   \n",
       "10849                               Jack Cashill   \n",
       "\n",
       "                                                    text  \\\n",
       "id                                                         \n",
       "7048   CHARLOTTE, N. C.  —   The fatal police shootin...   \n",
       "7891   Senator Bernie Sanders of Vermont, his preside...   \n",
       "3872   The Great Wall Street/Washington Con Job: Part...   \n",
       "6379   (Want to get this briefing by email? Here’s th...   \n",
       "15104  Catherine Engelbrecht, president of True the V...   \n",
       "...                                                  ...   \n",
       "20278  Interesting juxtaposition of the week: The AE ...   \n",
       "13283  Videos Evidence Reveals Possible Link Between ...   \n",
       "7064   Meet the journalist facing 45 years in jail fo...   \n",
       "1936   Subscribe \\nA dumbfounded Canadian — Richard B...   \n",
       "10849  For those who are too young or too unwilling t...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "id                                                         \n",
       "7048   charlotte n c — fatal police shooting keith la...   \n",
       "7891   senator bernie sander vermont presidential cam...   \n",
       "3872   great wall streetwashington con job part 5 rec...   \n",
       "6379   want get briefing email ’ good evening ’ lates...   \n",
       "15104  catherine engelbrecht president true vote talk...   \n",
       "...                                                  ...   \n",
       "20278  interesting juxtaposition week ae show “ duck ...   \n",
       "13283  video evidence reveals possible link voting ma...   \n",
       "7064   meet journalist facing 45 year jail filming ta...   \n",
       "1936   subscribe dumbfounded canadian — richard brunt...   \n",
       "10849  young unwilling remember trip memory lane 1969...   \n",
       "\n",
       "                                             clean_title  \\\n",
       "id                                                         \n",
       "7048   know detail police shooting charlotte new york...   \n",
       "7891   bernie sander ’ new political group met staff ...   \n",
       "3872   great wall streetwashington con job part 5 rec...   \n",
       "6379   friday evening briefing hillary clinton donald...   \n",
       "15104  true vote ’ engelbrecht u verge ‘ systemic ’ v...   \n",
       "...                                                  ...   \n",
       "20278  ‘ duck dynasty ’ legacy real fake upfront new ...   \n",
       "13283  evidence reveals possible link voting machine ...   \n",
       "7064   journalist facing 45 year jail filming tar san...   \n",
       "1936   comment canadian man slam american ’ realize a...   \n",
       "10849                      29 hillary scandal early year   \n",
       "\n",
       "                                                  tokens  neg_cleaned_text  \\\n",
       "id                                                                           \n",
       "7048   [charlotte, n, c, —, fatal, police, shooting, ...             0.150   \n",
       "7891   [senator, bernie, sander, vermont, presidentia...             0.099   \n",
       "3872   [great, wall, streetwashington, con, job, part...             0.036   \n",
       "6379   [want, get, briefing, email, ’, good, evening,...             0.088   \n",
       "15104  [catherine, engelbrecht, president, true, vote...             0.090   \n",
       "...                                                  ...               ...   \n",
       "20278  [interesting, juxtaposition, week, ae, show, “...             0.058   \n",
       "13283  [video, evidence, reveals, possible, link, vot...             0.071   \n",
       "7064   [meet, journalist, facing, 45, year, jail, fil...             0.198   \n",
       "1936   [subscribe, dumbfounded, canadian, —, richard,...             0.125   \n",
       "10849  [young, unwilling, remember, trip, memory, lan...             0.154   \n",
       "\n",
       "       neu_cleaned_text  pos_cleaned_text  compound  neg_clean_title  \\\n",
       "id                                                                     \n",
       "7048              0.774             0.076   -0.9978            0.000   \n",
       "7891              0.752             0.150    0.9816            0.000   \n",
       "3872              0.800             0.163    0.9674            0.000   \n",
       "6379              0.747             0.166    0.9916            0.000   \n",
       "15104             0.818             0.092   -0.2075            0.307   \n",
       "...                 ...               ...       ...              ...   \n",
       "20278             0.807             0.135    0.9786            0.237   \n",
       "13283             0.734             0.195    0.9889            0.000   \n",
       "7064              0.743             0.059   -0.9966            0.154   \n",
       "1936              0.707             0.169    0.9178            0.177   \n",
       "10849             0.732             0.114   -0.9882            0.420   \n",
       "\n",
       "       neu_clean_title  pos_clean_title  compound  percent_stop  \n",
       "id                                                               \n",
       "7048             1.000            0.000    0.0000      0.004634  \n",
       "7891             1.000            0.000    0.0000      0.000000  \n",
       "3872             0.687            0.313    0.6249      0.000000  \n",
       "6379             1.000            0.000    0.0000      0.000000  \n",
       "15104            0.584            0.109   -0.7269      0.000000  \n",
       "...                ...              ...       ...           ...  \n",
       "20278            0.763            0.000   -0.4767      0.000000  \n",
       "13283            1.000            0.000    0.0000      0.000000  \n",
       "7064             0.846            0.000   -0.2500      0.000000  \n",
       "1936             0.544            0.279    0.3612      0.000000  \n",
       "10849            0.580            0.000   -0.4404      0.000000  \n",
       "\n",
       "[6839 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "X_test['tokens'] = X_test['cleaned_text'].apply(lambda x: x.split())\n",
    "x_test_combined = sentiment_maker(X_test, \"cleaned_text\")\n",
    "x_test_combined = sentiment_maker(x_test_combined, \"clean_title\")\n",
    "x_test_combined['percent_stop'] = x_test_combined['tokens'].apply(count_stop_words)\n",
    "x_test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atin3\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<13883x157717 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3821317 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(X_train['cleaned_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=X_train.index)\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Extract numerical sentiment & stop-word features\n",
    "X_train_extra = np.array(X_vec[[\"pos_cleaned_text\", \"neu_cleaned_text\", \"neg_cleaned_text\", \"percent_stop\"]])\n",
    "X_test_extra = np.array(x_test_combined[[\"pos_cleaned_text\", \"neu_cleaned_text\", \"neg_cleaned_text\", \"percent_stop\"]])\n",
    "\n",
    "# Stack TF-IDF matrix with additional features\n",
    "X_train_final = hstack([tfidf_matrix, X_train_extra])\n",
    "X_test_final = hstack([X_test_tfidf, X_test_extra])\n",
    "X_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing through Document Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    12144\n",
      "0     1739\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.8075742067553736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.19      0.20       857\n",
      "           1       0.88      0.90      0.89      5982\n",
      "\n",
      "    accuracy                           0.81      6839\n",
      "   macro avg       0.55      0.54      0.54      6839\n",
      "weighted avg       0.80      0.81      0.80      6839\n",
      "\n",
      "y_test distribution: [ 857 5982]\n",
      "y_pred distribution: [ 779 6060]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "3551     1\n",
       "3609     1\n",
       "9200     1\n",
       "17811    1\n",
       "19853    1\n",
       "        ..\n",
       "18388    1\n",
       "18771    1\n",
       "2261     1\n",
       "10405    1\n",
       "15214    1\n",
       "Name: label, Length: 13883, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# Train Naïve Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_final, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Predict on test set\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train_final, y_train)\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"y_test distribution:\", np.bincount(y_test))\n",
    "print(\"y_pred distribution:\", np.bincount(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
